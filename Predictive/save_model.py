import pandas as pd
import numpy as np
import re # Module pour les expressions rÃ©guliÃ¨res (manipulation de texte avancÃ©e)
from xgboost import XGBRegressor # Le modÃ¨le "Champion", souvent plus fort que Random Forest
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
import joblib # INDISPENSABLE : C'est lui qui permet de sauvegarder le modÃ¨le dans un fichier

# =========================================================
# 1. CHARGEMENT ET NETTOYAGE (LOGIQUE 71%)
# =========================================================
# Cette partie est cruciale : on prÃ©pare les ingrÃ©dients avant de cuisiner.

print("â³ Chargement des donnÃ©es...")
try:
    df = pd.read_csv("data.csv")
except FileNotFoundError:
    print("âŒ Fichier 'data.csv' introuvable.")
    exit()

# --- A. Filtrage des Outliers (Valeurs extrÃªmes) ---
# Pourquoi ? Si tu as des chÃ¢teaux Ã  10 000$ ou des erreurs Ã  0$,
# cela perturbe le modÃ¨le. On garde les 98% "normaux" (entre 1% et 99%).
target = 'log_price'
low, high = df[target].quantile(0.01), df[target].quantile(0.99)
df = df[(df[target] >= low) & (df[target] <= high)]
print(f"âœ… Outliers filtrÃ©s. Lignes restantes : {len(df)}")

# --- B. Nettoyage de base ---
# On remplace les vides (NaN) par du texte vide pour Ã©viter les bugs lors des calculs de texte.
df['amenities'] = df['amenities'].fillna("")
df['description'] = df['description'].fillna("")

# --- C. Feature Engineering (CrÃ©ation de nouvelles colonnes) ---
# C'est l'art de donner des indices supplÃ©mentaires au modÃ¨le.

# 1. Compter les Ã©quipements et la longueur de la description
# Le modÃ¨le ne sait pas lire "TV, Wifi, Pool", mais il comprend "3 Ã©quipements".
df['amenities_count'] = df['amenities'].apply(lambda x: len(str(x).split(',')) if x else 0)
df['description_len'] = df['description'].apply(lambda x: len(str(x)) if x else 0)

# 2. Parsing des Ã©quipements Premium (La technique "One-Hot manuelle")
# On nettoie le texte des Ã©quipements (enlÃ¨ve les accolades {} et guillemets "")
df['amenities_clean'] = df['amenities'].str.replace('[{}"/]', '', regex=True)

# Liste des mots-clÃ©s qui font augmenter le prix
premium_amenities = ['Wifi', 'Air conditioning', 'Pool', 'Kitchen', 'Free parking', 'Gym', 'Hot tub', 'View']
new_cols = []

# Pour chaque mot-clÃ©, on crÃ©e une colonne (ex: has_pool) avec 1 (oui) ou 0 (non)
for item in premium_amenities:
    col_name = f'has_{item.replace(" ", "_").lower()}'
    # .str.contains cherche le mot dans le texte
    df[col_name] = df['amenities_clean'].str.contains(item, case=False, regex=False).astype(int)
    new_cols.append(col_name)

# 3. Dates (Transformation en durÃ©e)
# Les ordis ne comprennent pas "12 Janvier 2015". Ils comprennent "Actif depuis 500 jours".
now = pd.to_datetime('2017-10-01') # Date de rÃ©fÃ©rence (fixÃ©e pour l'exercice)
for col in ['host_since', 'last_review']:
    df[col] = pd.to_datetime(df[col], errors='coerce') # Convertit en format Date

# On calcule la diffÃ©rence en jours
df['host_days_active'] = (now - df['host_since']).dt.days
df['days_since_review'] = (now - df['last_review']).dt.days

# =========================================================
# 2. DÃ‰FINITION DES COLONNES (IDENTIQUE AU MODÃˆLE 3)
# =========================================================
# On liste ce qui rentre dans le modÃ¨le.
# Note : on ajoute les nouvelles colonnes crÃ©Ã©es plus haut (new_cols, amenities_count...)

# Variables CatÃ©gorielles (Texte -> deviendra des 0 et 1)
categorical_features = ['property_type', 'room_type', 'cancellation_policy', 'city', 'cleaning_fee', 'instant_bookable']

# Variables NumÃ©riques (Chiffres)
numeric_features = ['accommodates', 'bathrooms', 'bedrooms', 'beds', 'latitude', 'longitude',
                    'number_of_reviews', 'review_scores_rating', 'amenities_count',
                    'description_len', 'host_days_active', 'days_since_review'] + new_cols

# SÃ©paration X (Features) et y (Cible)
X = df[numeric_features + categorical_features]
y = df[target]

# =========================================================
# 3. CRÃ‰ATION DU PIPELINE DE PRODUCTION
# =========================================================
# Le Pipeline est la chaÃ®ne de montage automatisÃ©e.

# Le prÃ©processeur gÃ¨re les NaNs et l'encodage texte automatiquement
preprocessor = ColumnTransformer(
    transformers=[
        # Pour les chiffres : on remplace les trous par la mÃ©diane
        ('num', SimpleImputer(strategy='median'), numeric_features),
        # Pour le texte : OneHotEncoder.
        # sparse_output=False : crÃ©e un tableau normal lisible.
        # handle_unknown='ignore' : CRUCIAL. Si demain une nouvelle ville apparait, le modÃ¨le ne plantera pas (il mettra 0).
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
    ])

# ModÃ¨le XGBoost
# XGBoost construit les arbres les uns aprÃ¨s les autres pour corriger les erreurs des prÃ©cÃ©dents.
model = XGBRegressor(
    n_estimators=1000,    # 1000 arbres (c'est beaucoup, donc prÃ©cis)
    learning_rate=0.05,   # Vitesse d'apprentissage lente pour Ã©viter le surapprentissage
    max_depth=6,          # Profondeur max des arbres
    n_jobs=-1,            # Utilise tous les coeurs du CPU
    random_state=42
)

# Pipeline final : D'abord le nettoyage, ensuite le modÃ¨le
pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                           ('model', model)])

# =========================================================
# 4. ENTRAÃNEMENT ET VALIDATION
# =========================================================
# Ici, on teste d'abord si le modÃ¨le est bon en le coupant en deux.

print("\n" + "="*40)
print("ğŸ” VALIDATION AVANT SAUVEGARDE")
print("="*40)

# On coupe : 80% train, 20% test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# On entraÃ®ne sur les 80%
pipeline.fit(X_train, y_train)
# On prÃ©dit sur les 20% cachÃ©s
y_pred = pipeline.predict(X_test)

# On note la performance
score_r2 = r2_score(y_test, y_pred)
print(f"ğŸ“Š PrÃ©cision RÂ² : {score_r2:.2%}") # Affiche en pourcentage (ex: 72.50%)

if score_r2 > 0.70:
    print("ğŸš€ Score excellent (> 70%) ! PrÃ©paration du modÃ¨le final...")
else:
    print("âš ï¸  Le score est un peu plus bas que prÃ©vu. VÃ©rifie tes hyperparamÃ¨tres.")

# =========================================================
# 5. SAUVEGARDE FINALE
# =========================================================
# C'est l'Ã©tape "Mise en production".

# Pourquoi on refait un fit ?
# Maintenant qu'on sait que le modÃ¨le marche bien (grÃ¢ce Ã  l'Ã©tape 4),
# on veut qu'il apprenne sur 100% des donnÃ©es pour Ãªtre le plus intelligent possible
# avant de l'enregistrer dans un fichier.
print("\nğŸ”„ EntraÃ®nement final sur 100% du dataset...")
pipeline.fit(X, y)

# On sauvegarde tout le pipeline (nettoyage + modÃ¨le) dans un fichier .pkl
output_file = 'airbnb_model_prod.pkl'
joblib.dump(pipeline, output_file)

print(f"âœ… MODÃˆLE SAUVEGARDÃ‰ : {output_file}")
print("ğŸ’¡ Dans ton App Streamlit, tu n'auras qu'Ã  faire : model = joblib.load('airbnb_model_prod.pkl')")