import streamlit as st  # La librairie magique pour cr√©er l'app web
import pandas as pd
import numpy as np
import re  # Pour nettoyer les noms de colonnes (XGBoost/LightGBM n'aiment pas les caract√®res bizarres)
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score

# Les 3 Mousquetaires (Les mod√®les concurrents)
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor

# ==========================================
# 1. CONFIGURATION DE LA PAGE
# ==========================================
# D√©finit le titre de l'onglet du navigateur et utilise toute la largeur de l'√©cran
st.set_page_config(page_title="Airbnb IA - Battle Royale", layout="wide")

st.title("ü•ä Airbnb Battle Royale : RF vs XGBoost vs LightGBM")
st.markdown("---")  # Une ligne de s√©paration horizontale

# ==========================================
# 2. PARAM√àTRES (BARRE LAT√âRALE / SIDEBAR)
# ==========================================
# Tout ce qui commence par st.sidebar se met dans le volet gauche.

st.sidebar.header("1. Donn√©es")
# Champ texte pour dire o√π est le fichier
csv_path = st.sidebar.text_input("Chemin CSV", "data.csv")
# Case √† cocher pour activer/d√©sactiver le nettoyage des prix extr√™mes
remove_outliers = st.sidebar.checkbox("Filtrer Outliers (Prix extr√™mes)", value=True)

st.sidebar.header("2. Param√®tres IA")
# Slider pour choisir la taille du test (5% √† 50%)
test_size = st.sidebar.slider("Test Set Size", 0.05, 0.5, 0.2)
random_state = st.sidebar.number_input("Seed", 0, 9999, 42)  # Pour figer le hasard

st.sidebar.markdown("---")
# --- Configuration du Random Forest ---
st.sidebar.subheader("üå≤ RandomForest")
rf_est = st.sidebar.slider("RF - Arbres", 50, 500, 250, 10)  # Combien d'arbres ?
rf_depth = st.sidebar.slider("RF - Depth Max", 5, 50, 22)  # Profondeur max

st.sidebar.markdown("---")
# --- Configuration de XGBoost ---
st.sidebar.subheader("üöÄ XGBoost")
xgb_est = st.sidebar.slider("XGB - Estimators", 100, 2000, 1000, 100)
xgb_depth = st.sidebar.slider("XGB - Max Depth", 3, 10, 6)  # XGBoost pr√©f√®re des arbres peu profonds
xgb_lr = st.sidebar.slider("XGB - Learning Rate", 0.01, 0.3, 0.05)  # Vitesse d'apprentissage

st.sidebar.markdown("---")
# --- Configuration de LightGBM ---
# LightGBM est souvent plus rapide que XGBoost
st.sidebar.subheader("‚ö° LightGBM")
lgbm_est = st.sidebar.slider("LGBM - Estimators", 100, 2000, 1000, 100)
lgbm_depth = st.sidebar.slider("LGBM - Max Depth", -1, 15, -1)  # -1 veut dire "illimit√©"
lgbm_lr = st.sidebar.slider("LGBM - Learning Rate", 0.01, 0.3, 0.05)

st.sidebar.markdown("---")
# Combien d'exemples on veut voir dans le tableau comparatif √† la fin
nb_samples = st.sidebar.slider("Exemples pour le tableau final", 1, 50, 10)

# Le bouton qui d√©clenche tout le processus
do_train = st.sidebar.button("üöÄ LANCER LA BATAILLE")


# ==========================================
# 3. PR√âPARATION DES DONN√âES (CACHE)
# ==========================================
# @st.cache_data est important pour optimiser Streamlit.
# Si les param√®tres d'entr√©e (ici le chemin CSV) ne changent pas,
# Streamlit va r√©utiliser les donn√©es d√©j√† charg√©es au lieu de relire le CSV √† chaque clic.
@st.cache_data
def load_and_prep_data(path):
    # --- Chargement du CSV ---
    df = pd.read_csv(path)

    # --- Nettoyage basique ---
    # Remplissage des valeurs manquantes dans 'amenities' et 'description' par des cha√Ænes vides
    # Cela √©vite les erreurs lors des transformations suivantes
    df['amenities'] = df['amenities'].fillna("")
    df['description'] = df['description'].fillna("")

    # --- Feature Engineering ---
    # Cr√©ation de nouvelles colonnes √† partir des donn√©es existantes pour enrichir le dataset

    # Nombre d'√©quipements list√©s dans 'amenities'
    df['amenities_count'] = df['amenities'].apply(lambda x: len(str(x).split(',')) if x else 0)

    # Longueur de la description (nombre de caract√®res)
    df['description_len'] = df['description'].apply(lambda x: len(str(x)) if x else 0)

    # Nettoyage du texte des √©quipements pour enlever caract√®res sp√©ciaux
    df['amenities_clean'] = df['amenities'].str.replace('[{}"/]', '', regex=True)

    # --- One-Hot Encoding manuel pour √©quipements "premium" ---
    # On cr√©e une colonne binaire pour chaque √©quipement consid√©r√© important
    premium = ['Wifi', 'Air conditioning', 'Pool', 'Kitchen', 'Free parking', 'Gym', 'Hot tub', 'View']
    new_cols = []  # liste des nouvelles colonnes cr√©√©es
    for item in premium:
        col_name = f'has_{item.replace(" ", "_").lower()}'  # nom de la colonne propre
        # 1 si l'√©quipement est pr√©sent, 0 sinon
        df[col_name] = df['amenities_clean'].str.contains(item, case=False, regex=False).astype(int)
        new_cols.append(col_name)

    # --- Gestion des dates ---
    # On convertit les colonnes dates en objets datetime
    now = pd.to_datetime('2017-10-01')  # r√©f√©rence pour calcul des dur√©es
    for col in ['host_since', 'last_review']:
        df[col] = pd.to_datetime(df[col], errors='coerce')  # 'coerce' remplace les erreurs par NaN

    # Cr√©ation de nouvelles variables num√©riques bas√©es sur les dates
    df['host_days_active'] = (now - df['host_since']).dt.days  # nombre de jours depuis l'inscription de l'h√¥te
    df['days_since_review'] = (now - df['last_review']).dt.days  # nombre de jours depuis le dernier commentaire

    # --- Remplissage des valeurs manquantes ---
    # Pour les colonnes num√©riques : on remplace par la m√©diane
    num_fills = ['host_days_active', 'days_since_review', 'bathrooms', 'bedrooms', 'beds', 'review_scores_rating']
    for col in num_fills:
        if col in df.columns:
            df[col] = df[col].fillna(df[col].median())

    # Pour les colonnes cat√©gorielles : on remplace par "Unknown" et on force le type string
    cat_feats = ['property_type', 'room_type', 'cancellation_policy', 'city', 'cleaning_fee', 'instant_bookable']
    for col in cat_feats:
        if col in df.columns:
            df[col] = df[col].fillna("Unknown").astype(str)

    # --- Filtrage des Outliers (optionnel selon la checkbox) ---
    target = 'log_price'
    if remove_outliers:
        # On √©limine les 1% plus bas et 1% plus hauts du prix
        low, high = df[target].quantile(0.01), df[target].quantile(0.99)
        df = df[(df[target] >= low) & (df[target] <= high)]

    # --- S√©lection finale des colonnes utiles ---
    # Colonnes num√©riques de base
    base_nums = ['accommodates', 'bathrooms', 'bedrooms', 'beds', 'latitude', 'longitude',
                 'number_of_reviews', 'review_scores_rating', 'amenities_count',
                 'description_len', 'host_days_active', 'days_since_review']

    # On garde les colonnes num√©riques + colonnes premium + colonnes cat√©gorielles
    final_cols = [c for c in (base_nums + new_cols + cat_feats) if c in df.columns]

    # Retourne le DataFrame pr√©par√©, les colonnes finales, les colonnes cat√©gorielles et la cible
    return df, final_cols, cat_feats, target


# ==========================================
# 4. EX√âCUTION ET AFFICHAGE
# ==========================================
# Le code ci-dessous ne s'ex√©cute que si on clique sur le bouton "LANCER"
if do_train:
    # 1. Chargement des donn√©es via la fonction cach√©e
    df_full, final_cols, cat_feats, target = load_and_prep_data(csv_path)

    # Affiche un petit spinner "Chargement..." pendant les calculs
    with st.spinner("üß† Les mod√®les s'affrontent..."):

        # --- Pr√©paration finale pour Scikit-Learn ---
        X_raw = df_full[final_cols].copy()

        # get_dummies transforme le texte en colonnes de 0 et 1 (One-Hot Encoding)
        # drop_first=True √©vite la redondance (ex: si pas Paris et pas Lyon, c'est forc√©ment Marseille)
        X_encoded = pd.get_dummies(X_raw, columns=cat_feats, drop_first=True).fillna(0)

        # NETTOYAGE CRITIQUE DES NOMS DE COLONNES
        # XGBoost et LightGBM plantent s'il y a des espaces ou symboles <, >, [ ] dans les noms de colonnes
        X_encoded = X_encoded.rename(columns=lambda x: re.sub('[^A-Za-z0-9_]+', '', x))

        y = df_full[target]

        # S√©paration Train/Test
        X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=test_size,
                                                            random_state=random_state)

        # --- Entra√Ænement des 3 Mod√®les ---

        # 1. Random Forest
        model_rf = RandomForestRegressor(
            n_estimators=rf_est,
            max_depth=rf_depth,
            min_samples_split=7,
            max_features=None,
            n_jobs=-1,
            random_state=random_state
        )
        model_rf.fit(X_train, y_train)

        # 2. XGBoost
        model_xgb = XGBRegressor(n_estimators=xgb_est, max_depth=xgb_depth, learning_rate=xgb_lr, n_jobs=-1,
                                 random_state=random_state)
        model_xgb.fit(X_train, y_train)

        # 3. LightGBM (Souvent le plus rapide)
        model_lgbm = LGBMRegressor(n_estimators=lgbm_est, max_depth=lgbm_depth, learning_rate=lgbm_lr, n_jobs=-1,
                                   random_state=random_state, verbose=-1)  # verbose=-1 pour le faire taire
        model_lgbm.fit(X_train, y_train)

    # --- SECTION 1 : DASHBOARD DES SCORES ---
    st.header("üìä Scoreboard Final")

    # Calcul des scores R¬≤ (Pr√©cision globale)
    r2_rf = r2_score(y_test, model_rf.predict(X_test))
    r2_xgb = r2_score(y_test, model_xgb.predict(X_test))
    r2_lgbm = r2_score(y_test, model_lgbm.predict(X_test))

    scores = {"RandomForest": r2_rf, "XGBoost": r2_xgb, "LightGBM": r2_lgbm}
    # Trouve qui a le score max
    winner_name = max(scores, key=scores.get)

    # Affichage en 3 colonnes
    c1, c2, c3 = st.columns(3)
    c1.metric("üå≤ RandomForest", f"{r2_rf:.2%}")
    c2.metric("üöÄ XGBoost", f"{r2_xgb:.2%}")
    c3.metric("‚ö° LightGBM", f"{r2_lgbm:.2%}")

    # Annonce du vainqueur + Ballons
    st.success(f"üèÜ Le gagnant est **{winner_name}** avec **{scores[winner_name]:.2%}** de pr√©cision !")
    st.balloons()

    # --- SECTION 2 : ANALYSE D√âTAILL√âE ---
    st.divider()
    # Cr√©ation d'onglets pour organiser l'affichage
    t1, t2 = st.tabs(["üî¨ Comparaison par Annonce", "üìà Importance des Variables"])

    # Onglet 1 : Tableau comparatif
    with t1:
        st.subheader(f"Top {nb_samples} pr√©dictions (Prix en $)")
        # On prend quelques lignes au hasard dans le test
        idx = np.random.choice(X_test.index, size=min(nb_samples, len(X_test)), replace=False)

        # On cr√©e un tableau comparatif
        # np.exp() est INDISPENSABLE car on a pr√©dit le log_price, il faut revenir au prix r√©el ($)
        comp_df = pd.DataFrame({
            "R√©el": np.exp(y_test.loc[idx]),
            "Pred_RF": np.exp(model_rf.predict(X_test.loc[idx])),
            "Pred_XGB": np.exp(model_xgb.predict(X_test.loc[idx])),
            "Pred_LGBM": np.exp(model_lgbm.predict(X_test.loc[idx]))
        })

        # Calcul de l'erreur pour le gagnant
        winning_model = {"RandomForest": model_rf, "XGBoost": model_xgb, "LightGBM": model_lgbm}[winner_name]
        prefix = 'RF' if winner_name == 'RandomForest' else 'XGB' if winner_name == 'XGBoost' else 'LGBM'
        comp_df["Erreur ($)"] = abs(comp_df["R√©el"] - comp_df[f"Pred_{prefix}"])

        # Affichage stylis√© avec couleurs (Rouge = grosse erreur, Vert = bonne pr√©diction)
        st.dataframe(comp_df.style.format("{:.0f}")
                     .background_gradient(subset=["Erreur ($)"], cmap="Reds")
                     .highlight_min(subset=["Pred_RF", "Pred_XGB", "Pred_LGBM"], color="lightgreen", axis=1))

    # Onglet 2 : Feature Importance (Qu'est-ce qui compte le plus ?)
    with t2:
        st.subheader(f"Qu'est-ce qui influence le prix selon {winner_name} ?")
        # On r√©cup√®re les importances calcul√©es par le mod√®le gagnant
        importances = winning_model.feature_importances_
        # On trie pour avoir les plus grandes barres en haut
        feat_imp = pd.Series(importances, index=X_train.columns).sort_values(ascending=False).head(15)

        # Graphique
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.barplot(x=feat_imp.values, y=feat_imp.index, palette="viridis", ax=ax)
        ax.set_title(f"Top 15 Features - {winner_name}")
        st.pyplot(fig)  # Affiche le graphique matplotlib dans Streamlit

else:
    # Message d'accueil si on n'a pas encore cliqu√©
    st.info("üëà Configure tes mod√®les et lance la bataille dans la barre lat√©rale !")